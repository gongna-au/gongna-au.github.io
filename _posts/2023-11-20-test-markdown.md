---
layout: post
title: 测试之道
subtitle:
tags: [测试]
comments: true
---

### BDD

BDD（行为驱动开发）
本质:
专注于系统行为和业务逻辑。
通常使用自然语言描述，易于非技术人员理解。
将需求和测试紧密结合。
应用场景:
当需要与非技术人员（如产品经理或业务分析师）讨论需求时。
当想强调软件应该做什么，而不是怎么做。

在BDD（行为驱动开发）中，自然语言描述通常遵循“Given-When-Then”的模式。

统一模板：
```text
Feature: [功能描述]

  Scenario: [场景描述]
    Given [前置条件]
    When [操作或事件]
    Then [预期结果]

```

```text
Feature: 计算器的加法功能

  Scenario: 两个正数的加法
    Given 计算器已开启
    When 输入数字 1 和 2 进行加法运算
    Then 结果应为 3

  Scenario: 加法与清零功能
    Given 计算器已开启并显示结果为 3
    When 按下清零键
    Then 显示结果应为 0
```

### TDD

TDD（测试驱动开发）
本质:
先编写测试，然后编写满足测试的最简代码。
侧重于开发过程，而不仅仅是测试。
应用场景:
适用于几乎所有软件项目，特别是新项目。
当想确保的代码能正常工作，并且容易维护。

### MBT
MBT（模型驱动测试）
本质:
使用模型（通常是状态机或图）来描述系统行为。
根据模型自动生成测试用例。
应用场景:
当系统非常复杂，并且状态转换多。
适用于硬件测试，或者需要与硬件交互的软件。
当手动编写和维护测试用例成本过高。
总结：BDD强调业务和行为，TDD强调开发过程，而MBT强调通过模型来自动化和简化测试。根据的项目需求，可能会选择其中一个，或者将它们结合使用。

## 性能分析方法


### Load Testing（负载测试）
优点: 用于模拟多用户并发访问，找出系统在高负载下的性能瓶颈。
缺点: 需要大量的资源和时间来模拟真实环境。

### Profiling（性能剖析）
优点: 可以深入到代码级别，找出性能问题的具体来源。
缺点: 对代码有侵入性，可能会影响系统的正常运行。

### Monitoring（实时监控）
优点: 在生产环境下收集数据，非常接近实际情况。
缺点: 只能发现问题，但不一定能定位问题源。

### Stress Testing（压力测试）
优点: 能找出系统的极限性能。
缺点: 不一定适用于所有场景，且可能会影响现有用户。

### APM Tools（应用性能管理工具）
优点: 提供全面的性能指标，包括延迟、错误率等。
缺点: 通常需要购买商业软件，成本高。

### Database Query Analysis（数据库查询分析）
优点: 针对数据库性能瓶颈进行优化。
缺点: 专注于数据库，可能会忽视其他问题。

### Code Review（代码审查）
优点: 通过人工检查来预防性能问题。
缺点: 很依赖个人经验，可能会漏掉一些非明显的问题。

## JMeter 

概述、安装 JMeter 和插件 

第一个构建块 

常用元素 - 线程组 
常用元素 - 配置元素 
常用元素 - HTTP 请求采样器 


常用元素 - 听众 
常用元素 - 控制器 
常用元素 - 控制器 


常用元素 - 计时器 
节奏与思考时间 
范围规则和执行顺序 
知识检查#4
利用数据集 
JMeter 日志记录 
后处理器 - 正则表达式、JSON 路径、边界提取器 
使用 HTTP(S) 测试脚本记录器创建脚本 
使用 JMeter 变量和属性测试参数化



## Linux相关


理论题/选择题：

> 简要描述Linux三剑客（awk、grep、sed）各自的主要用途。

awk：主要用于文本和数据提取及处理。它可以定义多种文本操作任务，并在文件或输入流中的每一行上执行这些任务。

grep：用于在文本文件中搜索匹配特定模式的行。非常适用于快速文本搜索。

sed：主要用于流式文本编辑，可以对输入的文本进行各种替换、删除、插入等操作。

> 使用awk对给定的文本文件进行特定字段的提取。

假设有一个逗号分隔的文本文件data.csv，内容如下：
```shell
Copy code
John,25,Engineer
Sarah,30,Doctor
```
可以使用下面的awk命令来提取第一个和第三个字段：

```shell
awk -F',' '{print $1, $3}' data.csv
```

> 使用sed进行文本替换。

假设你有一个文本文件text.txt，内容如下：
```shell
Hello World
```
可以使用下面的sed命令来替换"World"为"Universe"：

```shell
sed 's/World/Universe/g' text.txt
```
> 编写一个grep命令，找出包含或不包含某些特定字符串的行。

使用grep找出包含或不包含某些特定字符串的行

假设你有一个文本文件sample.txt，内容如下：
```text
apple
orange
banana
```
找出包含apple的行：

```shell
grep 'apple' sample.txt
```
找出不包含apple的行：
```shell
grep -v 'apple' sample.txt
```
> 什么是iptables？它在网络配置中主要用于什么？

iptables是Linux系统中的一个用户空间工具，用于配置内核防火墙。在网络配置中，它主要用于定义一套规则，控制网络包的转发、接收和发送。

> 编写一个简单的iptables规则来阻止来自特定IP地址的所有网络流量。

```shell
sudo iptables -A INPUT -s 192.168.1.1 -j DROP
```
> 与tcpdump相关的命令是什么，它的作用是什么？

tcpdump：用于捕获和分析网络流量。它可以抓取经过一个网络接口的数据包，并提供详细的信息，如源/目的IP地址、源/目的端口等，以便进行网络诊断或分析。

> 使用tcpdump捕获特定类型的网络包。

例如，要捕获所有来自IP地址192.168.1.1的TCP包，你可以使用以下命令：
```shell
sudo tcpdump tcp and src 192.168.1.1
```

> 列出系统中运行的前5个占用CPU最多的进程。


```shell
ps -eo %cpu,command | sort -k1 -n -r | head -n 6
```
ps -eo %cpu,command: 运行ps命令来显示所有进程的CPU使用率（%cpu）和命令行（command）。

sort -k1 -n -r: 用sort命令按第一个字段（即CPU使用率）进行排序。选项-n表示按数值排序，-r表示逆序（从大到小）。

head -n 6: 使用head命令来只显示排序后的前6行。这里是6行而不是5行，因为第一行通常是列标题。

> 编写一个简单的Shell脚本，用于自动执行一系列的系统监测任务。

```shell
#!/bin/bash
echo "Disk Usage:"
df -h
echo "Memory Usage:"
free -m
echo "CPU Load:"
top -n 1  | grep "Load Avg"
```


> 发现一个服务器突然响应缓慢，你会用哪些命令或方法来诊断问题？

top或htop：查看CPU和内存使用情况。
iotop：检查磁盘I/O。
sudo fs_usage:MacOS不自带iotop工具。可以使用sudo fs_usage来监视文件系统的使用情况，但这不是iotop的直接替代。
netstat：检查网络连接。
dmesg | tail：查看内核日志的最后几行。

> 优化系统或网络性能：

诊断：
使用top和iotop诊断了系统和IO性能。
使用tcpdump和iptables记录来自特定IP地址的网络流量。
数据库查询日志也被审查以找出低效的查询。

解决方案：
优化数据库查询： 发现某些复杂的SQL查询没有使用索引，导致查询效率低下。通过添加索引，查询时间得以显著减少。

网络优化：
发现TCP连接中有大量的TIME_WAIT状态。通过调整/proc/sys/net/ipv4/tcp_tw_reuse和/proc/sys/net/ipv4/tcp_tw_recycle的值，减少了TIME_WAIT连接数。
使用iptables限制了来自某些可疑IP地址的访问，减轻了服务器的负担。
使用缓存： 对于频繁访问的数据库查询结果，使用了Redis作为缓存，进一步减少了数据库的负担。
负载均衡： 为了分散流量，引入了一个负载均衡器，并对其进行了精细的配置。



# 软件测试45讲学习笔记


前言：

> 很多人第一印象会觉得做测试比做开发简单很多，但是我想说，在这个世界上，你想把任何一件事做好、做到极致都没那么容易.

> 类别：嵌入式系统测试、金融平台单元测试、平台 SDK 测试、轨道交通安全软件测试、Web Service 测试、大型电商网站 GUI 自动化以及性能全链路压测等。

> 能力要求：测试工程师的知识面、测试设计能力、测试开发能力和测试平台化抽象能力

> 具体要求：需要从业务本身出发来对软件进行手工测试验证，还需要掌握完整的自动化测试开发技术来设计自动化测试用例。

> 测试数据的准备工具化，服务化，最终实现平台化。

> 快速学习的能力，能迅速掌握被测软件的业务功能与内部架构,.并在此基础上运用各种测试方法，尽可能多地发现潜在缺陷，并能够在已知缺陷的基础上进一步发现相关的连带缺陷。

> 第一步，成为互联网时代合格的测试工程师。比开发人员更全面的计算机基础知识,了解基础架构，安全攻击，软件性能，用户体验。

> 第二步，成为互联网时代优秀的测试工程师。，合格的测试工程师关注的是纯粹的测试，而优秀的测试工程师关注更多的是软件整体的质量

> 第三步，成为互联网时代的测试架构师。无论是 GUI 还是 API，都需要一套高效的能够支持高并发的测试执行基础架构；再比如，面对测试过程中的大量差异性数据要求，需要统一的测试数据准备平台；再比如，为了可以更方便地和持续集成与发布系统（CI/CD）以解耦的形式做集成，需要统一发起测试执行的接口。

## 01 | 用户登陆测试


> 黑盒测试方法

等价类划分方法，是将所有可能的输入数据划分成若干个子集，在每个子集中，如果任意一个输入数据对于揭露程序中潜在错误都具有同等效果，那么这样的子集就构成了一个等价类。后续只要从每个等价类中任意选取一个值进行测试，就可以用少量具有代表性的测试输入取得较好的测试覆盖结果。

边界值分析方法，是选取输入、输出的边界值进行测试。因为通常大量的软件错误是发生在输入或输出范围的边界上，所以需要对边界值进行重点测试，通常选取正好等于、刚刚大于或刚刚小于边界的值作为测试数据。


现在，针对“用户登录”功能，基于等价类划分和边界值分析方法，我们设计的测试用例包括：
输入已注册的用户名和正确的密码，验证是否登录成功；
输入已注册的用户名和不正确的密码，验证是否登录失败，并且提示信息正确；
输入未注册的用户名和任意密码，验证是否登录失败，并且提示信息正确；
用户名和密码两者都为空，验证是否登录失败，并且提示信息正确；
用户名和密码两者之一为空，验证是否登录失败，并且提示信息正确；
如果登录功能启用了验证码功能，在用户名和密码正确的前提下，输入正确的验证码，验证是否登录成功；
如果登录功能启用了验证码功能，在用户名和密码正确的前提下，输入错误的验证码，验证是否登录失败，并且提示信息正确。


经验的测试工程师会再增加的测试用例：
用户名和密码是否大小写敏感；
页面上的密码框是否加密显示；
后台系统创建的用户第一次登录成功时，是否提示修改密码；
忘记用户名和忘记密码的功能是否可用；
前端页面是否根据设计要求限制用户名和密码长度；
如果登录功能需要验证码，点击验证码图片是否可以更换验证码，更换后的验证码是否可用；
刷新页面是否会刷新验证码；
如果验证码具有时效性，需要分别验证时效内和时效外验证码的有效性；
用户登录成功但是会话超时后，继续操作是否会重定向到用户登录界面；
不同级别的用户，比如管理员用户和普通用户，登录系统后的权限是否正确；
页面默认焦点是否定位在用户名的输入框中；
快捷键 Tab 和 Enter 等，是否可以正常使用。

#### 功能性和非功能性（安全/性能/兼容性/风险/用户）

显式功能性需求（Functional requirement）的含义从字面上就可以很好地理解，指的是软件本身需要实现的具体功能， 比如“正常用户使用正确的用户名和密码可以成功登录”、“非注册用户无法登录”等，这都是属于典型的显式功能性需求描述。
那什么是非功能性需求（Non-functional requirement）呢？从软件测试的维度来看，非功能性需求主要涉及安全性、性能以及兼容性三大方面。 在上面所有的测试用例设计中，我们完全没有考虑对非功能性需求的测试，但这些往往是决定软件质量的关键因素。


#### 安全性测试

用户密码后台存储是否加密；
用户密码在网络传输过程中是否加密；
密码是否具有有效期，密码有效期到期后，是否提示需要修改密码；
不登录的情况下，在浏览器中直接输入登录后的 URL 地址，验证是否会重新定向到用户登录界面；
密码输入框是否不支持复制和粘贴；
密码输入框内输入的密码是否都可以在页面源码模式下被查看；
用户名和密码的输入框中分别输入典型的“SQL 注入攻击”字符串，验证系统的返回页面；
用户名和密码的输入框中分别输入典型的“XSS 跨站脚本攻击”字符串，验证系统行为是否被篡改；
连续多次登录失败情况下，系统是否会阻止后续的尝试以应对暴力破解；
同一用户在同一终端的多种浏览器上登录，验证登录功能的互斥性是否符合设计预期；
同一用户先后在多台终端的浏览器上登录，验证登录是否具有互斥性。
是否可以使用登录的API发送登录请求，并绕开验证码校验
是否可以用抓包工具抓到的请求包直接登录
截取到的token等信息，是否可以在其他终端上直接使用，绕开登录。token过期时间校验
除了前端校验格式长度等，后端是否也校验？
登录后输入登录URL，是否还能再次登录？如果能，原登录用户是否变得无效
登录错误后的提示是否有安全隐患
  

#### 性能压力测试

单用户登录的响应时间是否小于 3 秒；
单用户登录时，后台请求数量是否过多；
高并发场景下用户登录的响应时间是否小于 5 秒；
高并发场景下服务端的监控指标是否符合预期；
高集合点并发场景下，是否存在资源死锁和不合理的资源等待；
长时间大量用户连续登录和登出，服务器端是否存在内存泄漏。

#### 兼容性测试

不同浏览器下，验证登录页面的显示以及功能正确性；
相同浏览器的不同版本下，验证登录页面的显示以及功能正确性；
不同移动设备终端的不同浏览器下，验证登录页面的显示以及功能正确性；
不同分辨率的界面下，验证登录页面的显示以及功能正确性。


#### 网络延迟和弱网络场景下的测试

网络延迟或者弱网或者切换网络或者断网时正常登录是否正常
是否支持第三方登录
是否可记住密码，记住的密码保存是否加密
记住密码是否有有效期，有有效期，过期之后是否会清空密码

常规用例中，用户名密码是否支持特殊字符和中文等

一个优秀的测试工程师必须具有很宽广的知识面，如果你不能对被测系统的设计有深入的理解、不明白安全攻击的基本原理、没有掌握性能测试的基本设计方法，很难设计出“有的放矢”的测试用例。、

> 站在用户的角度对需求有深入的了解，站在开发的角度对系统有深入的了解，同时站在安全的角度对系统安全有深入的了解，站在系统资源角度对系统性能有深入的了解

#### APP 端测试

1、登录失败后二次登录
（1）输入正确的用户名，不输入密码，点击登录；登录失败后，再次输入正确的密码登录并观察登录情况
（2）输入正确的用户名和错误的密码登录失败后，再次输入正确的密码登录并观察登录情况
（3）输入未注册的用户和任意密码登录失败后，再次输入正确的用户名和密码，观察登录情况
2、修改密码后
（1）修改完密码后是否重定向到登录界面
（2）修改完密码后，分别使用原密码和新密码登录
（3）在其他终端修改密码后，本终端是否自动下线？下线后，使用原密码能否继续登录？
3、退出登录
（1）退出登录是否有记住账号或记住密码功能
（2）退出登录后，再次输入密码登录
4、数据同步
（1）第一次登录时，数据的同步情况，如个人头像，好友列表等
（2）本终端切换其他账号登录后，数据的同步情况，日志记录情况，如：用户文件夹是否自动创建
5、账号互踢
（1）不同页面下被踢，如：后台运行时被踢，进入前台查看反应；前台运行时一级、二级页面下被踢能否提示正确并重 定向到登录界面
（2）本终端被踢下线后点击登录能否再次登录
6、密码错误限制次数
（1）密码输入错误是否有最大次数限制？分别测试最大值-1、最大值、最大值+1时的输错密码情况
（2）超过最大次数限制后，是否采取强制手段限制登录或对账号暂时冻结处理
（3）超过最大次数限制后，分别输入正确的密码和错误的密码再次登录
7、安全性
（1）本终端用户已登录，在其他终端尝试登录本用户账号登录失败时、本终端是否有账号异常操作的安全提示
（2）输入密码时是否有安全键盘模式？点击密码输入框是否能调起安全键盘？（参考各大手机银行APP）
8、网络相关
（1）无网络模式下登录，是否给出“网络未连接”或“网络异常”的提示及提示是否正确
（2）第一次登录请求超时后（服务器出问题，随后恢复正常），再次请求登录能否登录成功
（3）第一次无网络情况下登录失败后，再次连接网络并登录
（4）正在登录过程中，遇到网络切换，如（4G切换到WiFi环境时）能否正常登录
9、其他
（1）已登录的用户，杀死APP进程后，再次打开APP是否依然为已登录状态


#### 其他细节

1、为空和输入空字符串时的校验是否一致；
2、使用中文键盘输入字母时和使用英文键盘输入字母时传给后端的字符长度是否一致；
3、登录成功后的session时效设置；
4、安全性方面异地登录校验、更换设备登录校验、登录信息异常是否考虑账号冻结停用；是否允许第三方工具平台存储密码。


#### 资产风险

涉及资产风险的，对登录设备和地区检测


#### 浏览器缓存

否用到缓存

#### 用户体验

1、输入账号密码时对键盘格式是否有要求比如数字键盘；
2、密码一栏是否需要设置明暗码切换按钮；
3、输入账号密码格式不规范时是否将按钮设置为不可点击；
4、输入栏是否设置快速删除按钮

#### 总结

> 用例设计考验的是Tester的思维能力，而测试思维方式的培养是一个持续的过程。本人很认可《你的灯亮着吗》里的一段话：每一个解决方案都是下一个问题的来源，要真正理解问题，那至少对自己的解决方案提出三个可能出错的地方。

首先，对于高质量的软件测试，用例设计不仅需要考虑明确的显式功能性需求，还要涉及兼容性、安全性和性能等一系列的非功能性需求，这些非功能性需求对软件系统的质量有着举足轻重的作用。


## 02 | 如何设计好的测试用例

#### 思考：

> 什么是好的测试用例？

> 好的”测试用例必须具备哪些特征？

> 用什么方法来量化测试用例发现缺陷的可能性？

> 如何评估是否还存在未被发现的缺陷？如果软件中根本就没有错误了呢？


“好的”测试用例一定是一个完备的集合，它能够覆盖所有等价类以及各种边界值，而跟能否发现缺陷无关。

如果把被测试软件看作一个池塘，软件缺陷是池塘中的鱼，建立测试用例集的过程就像是在编织一张捕渔网。“好的”测试用例集就是一张能够覆盖整个池塘的大渔网，只要池塘里有鱼，这个大渔网就一定能把鱼给捞上来。


#### “好的”测试用例必须具备哪些特征？

一个“好的”测试用例，必须具备以下三个特征。
整体完备性： “好的”测试用例一定是一个完备的整体，是有效测试用例组成的集合，能够完全覆盖测试需求。
等价类划分的准确性： 指的是对于每个等价类都能保证只要其中一个输入测试通过，其他输入也一定测试通过。
等价类集合的完备性： 需要保证所有可能的边界值和边界条件都已经正确识别。


#### 最常用的软件测试方法

对大多数的软件测试而言，综合使用等价类划分、边界值分析和错误推测这三大类方法就足够了。


> 等价类划分方法-(等价类划分的关键就是找出无效等价类)

等价类中任意一个输入数据对于揭露程序中潜在错误都具有同等效果。后续我们只要从每个等价类中任意选取一个值进行测试，就可以用少量具有代表性的测试输入取得较好的测试覆盖结果。


一个具体的例子：学生信息系统中有一个“考试成绩”的输入项，成绩的取值范围是 0~100 之间的整数，考试成绩及格的分数线是 60。
为了测试这个输入项，显然不可能用 0~100 的每一个数去测试。通过需求描述可以知道，输入 0~59 之间的任意整数，以及输入 60~100 之间的任意整数，去验证和揭露输入框的潜在缺陷可以看做是等价的。
那么这就可以在 0~59 和 60~100 之间各随机抽取一个整数来进行验证。这样的设计就构成了所谓的“有效等价类”。
你不要觉得进行到这里，已经完成了等价类划分的工作，因为等价类划分方法的另一个关键点是要找出所有“无效等价类”。显然，如果输入的成绩是负数，或者是大于 100 的数等都构成了“无效等价类”。
在考虑了无效等价类后，最终设计的测试用例为：
有效等价类 1：0~59 之间的任意整数；
有效等价类 2：59~100 之间的任意整数；
无效等价类 1：小于 0 的负数；
无效等价类 2：大于 100 的整数；
无效等价类 3：0~100 之间的任何浮点数；
无效等价类 4：其他任意非数字字符


> 边界值分析方法

边界值分析是对等价类划分的补充，你从工程实践经验中可以发现，大量的错误发生在输入输出的边界值上，所以需要对边界值进行重点测试，通常选取正好等于、刚刚大于或刚刚小于边界的值作为测试数据。
我们继续看学生信息系统中“考试成绩”的例子，选取的边界值数据应该包括：-1，0，1，59，60，61，99，100，101。

> 错误推测方法

被测试软件的需求理解以及设计实现的细节把握，当然还有个人的能力。

比如，Web 界面的 GUI 功能测试，需要考虑浏览器在有缓存和没有缓存下的表现；Web Service 的 API 测试，需要考虑被测 API 所依赖的第三方 API 出错下的处理逻辑；对于代码级的单元测试，需要考虑被测函数的输入参数为空情况下的内部处理逻辑等等。由此可见，这些测试用例的设计都是基于曾经遇到的问题而进行的错误推测



#### 如何设计好的测试用例


只有真正理解了原始业务需求之后，才有可能从业务需求的角度去设计针对性明确、从终端用户使用场景考虑的端到端（End-2-End）的测试用例集。这个阶段的测试用例设计，主要目的是验证各个业务需求是否被满足，主要采用基于黑盒的测试设计方法。


在具体的用例设计时，首先需要搞清楚每一个业务需求所对应的多个软件功能需求点，然后分析出每个软件功能需求点对应的多个测试需求点，最后再针对每个测试需求点设计测试用例。


业务需求点——软件功能需求点——测试需求点



> 测试用例本身的设计上需要关注点

软件功能需求出发:

全面地、无遗漏地识别出测试需求是至关重要的，这将直接关系到用例的测试覆盖率。比如，如果你没有识别出用户登录功能的安全性测试需求，那么后续设计的测试用例就完全不会涉及安全性，最终造成重要测试漏洞。


在测试的需求点上：

综合运用等价类划分、边界值分析和错误推测方法来全面地设计测试用例。以“用户登录”的功能性测试需求为例，你首先应该对“用户名”和“密码”这两个输入项分别进行等价类划分，列出对应的有效等价类和无效等价类，对于无效等价类的识别可以采用错误猜测法（比如，用户名包含特殊字符等），然后基于两者可能的组合，设计出第一批测试用例。
等价类划分完后，你需要补充“用户名”和“密码”这两个输入项的边界值的测试用例，比如用户名为空（NULL）、用户名长度刚刚大于允许长度等。

从被测试软件的基础架构上：

作为测试工程师，切忌不能把整个被测系统看作一个大黑盒，你必须对内部的架构有清楚的认识，比如数据库连接方式、数据库的读写分离、消息中间件 Kafka 的配置、缓存系统的层级分布、第三方系统的集成等等。

从被测试软件的设计和实现细节上：

单单根据测试需求点设计的用例，只能覆盖“表面”的一层，往往会覆盖不到内部的处理流程、分支处理，而没有覆盖到的部分就很可能出现缺陷遗漏。在具体实践中，你可以通过代码覆盖率指标找出可能的测试遗漏点。同时，切忌不要以开发代码的实现为依据设计测试用例。因为开发代码实现的错误会导致测试用例也出错，所以你应该根据原始需求设计测试用例。

从需求覆盖率和代码覆盖率：

需要引入需求覆盖率和代码覆盖率来衡量测试执行的完备性，并以此为依据来找出遗漏的测试点。 关于什么是需求覆盖率和代码覆盖率，我会在后续的文章中详细介绍。


#### 总结

好的测试用例是一个完备的集合，覆盖所有等价类以及各种边界值，能否发现缺陷并不是衡量测试用例好坏的标准。

好的测试用例需要从软件功能需求、测试需求、基础架构、实现细节、代码覆盖、需求覆盖。

测试人员应该是对全线产品逻辑细节最熟知的，需求设计的业务漏洞也需要测试来把控



## 03 | 什么是单元测试

思考：

> 什么是单元测试？

> 单元测试的用例设计

> 单元测试的输入数据？

> 单元测试的输出数据？

> 什么是桩代码？

> 什么是驱动代码？

> 什么是Mock代码？


#### 什么是单元测试？
单元测试是指，对软件中的最小可测试单元在与程序其他部分相隔离的情况下进行检查和验证的工作，这里的最小可测试单元通常是指函数或者类。

单元测试的实施过程还可以帮助开发工程师改善代码的设计与实现，并能在单元测试代码里提供函数的使用示例，因为单元测试的具体表现形式就是对函数以各种不同输入参数组合进行调用，这些调用方法构成了函数的使用说明

#### 单元测试的方法

基本方法和主要技术手段，比如什么是驱动代码、桩代码和 Mock 代码等。

#### 单元测试的用例设计

单元测试的用例是一个“输入数据”和“预计输出”的集合，在明确了代码需要实现的逻辑功能的基础上，什么输入，应该产生什么输出”。

#### 单元测试的输入数据？

如果你想当然的认为只有被测试函数的输入参数是“输入数据”的话，那就大错特错了。

被测试函数的输入参数；
被测试函数内部需要读取的全局静态变量；
被测试函数内部需要读取的成员变量；
函数内部调用子函数获得的数据；
函数内部调用子函数改写的数据；
嵌入式系统中，在中断调用时改写的数据；


#### 单元测试的输出数据？

如果没有明确的预计输出，那么测试本身就失去了意义。同样地，“预计输出” 绝对不是只有函数返回值这么简单，还应该包括函数执行完成后所改写的所有数据。 具体来看有以下几大类：
被测试函数的返回值；
被测试函数的输出参数；
被测试函数所改写的成员变量；
被测试函数所改写的全局变量；
被测试函数中进行的文件更新；
被测试函数中进行的数据库更新；
被测试函数中进行的消息队列更新；


#### 驱动代码，桩代码和 Mock 代码

驱动代码是用来调用被测函数的，而桩代码和 Mock 代码是用来代替被测函数调用的真实代码的。


驱动代码（Driver）指调用被测函数的代码，在单元测试过程中，驱动模块通常包括调用被测函数前的数据准备、调用被测函数以及验证相关结果三个步骤。驱动代码的结构，通常由单元测试的框架决定。

桩代码（Stub）是用来代替真实代码的临时代码。 比如，某个函数 A 的内部实现中调用了一个尚未实现的函数 B，为了对函数 A 的逻辑进行测试，那么就需要模拟一个函数 B，这个模拟的函数 B 的实现就是所谓的桩代码。


桩函数要具有与原函数完全相同的原形，仅仅是内部实现不同，这样测试代码才能正确链接到桩函数；
用于实现隔离和补齐的桩函数比较简单，只需保持原函数的声明，加一个空的实现，目的是通过编译链接；
实现控制功能的桩函数是应用最广泛的，要根据测试用例的需要，输出合适的数据作为被测函数的内部输入


在我看来，Mock 代码和桩代码的本质区别是：测试期待结果的验证（Assert and Expectiation）


Mock和Stub都是用于模拟代码行为的，但它们的用途和关注点有些不同。下面用Go代码来举例说明这两者的区别。

Mock代码示例
Mock关注方法是否被调用，被怎样调用，以及调用次数等。

使用Go的popular mocking库 github.com/stretchr/testify/mock。

```go
package main

import (
	"testing"
	"github.com/stretchr/testify/mock"
)

type MyMockedObject struct {
	mock.Mock
}

func (m *MyMockedObject) DoSomething(number int) (bool, error) {
	args := m.Called(number)
	return args.Bool(0), args.Error(1)
}

func TestSomethingWithMock(t *testing.T) {
	testObject := new(MyMockedObject)

	// 设置期望
	testObject.On("DoSomething", 123).Return(true, nil)

	// 调用代码
	result, err := testObject.DoSomething(123)

	// 验证mock方法是否如期望那样被调用
	testObject.AssertExpectations(t)

	// 验证返回值
	if result != true || err != nil {
		t.Fail()
	}
}
```

Stub代码示例
Stub主要用于控制代码路径，不关心是否和如何被调用。

```go
package main

import (
	"testing"
)

type MyStubObject struct {
	DoSomethingFunc func(int) (bool, error)
}

func (m *MyStubObject) DoSomething(number int) (bool, error) {
	if m.DoSomethingFunc != nil {
		return m.DoSomethingFunc(number)
	}
	return false, nil
}

func TestSomethingWithStub(t *testing.T) {
	testObject := &MyStubObject{
		DoSomethingFunc: func(number int) (bool, error) {
			if number == 123 {
				return true, nil
			}
			return false, nil
		},
	}

	// 调用代码
	result, err := testObject.DoSomething(123)

	// 验证返回值
	if result != true || err != nil {
		t.Fail()
	}
}
```

在Mock的例子中，我们使用了testify/mock库来设置期望并在最后验证这些期望是否得到满足。
在Stub的例子中，我们直接在测试代码中设置了一个匿名函数来模拟DoSomething方法的行为。
这样，你可以清楚地看到Mock和Stub在测试中的不同用途和关注点。


#### 如何开展单元测试？


需要确定单元测试框架的选型，这和开发语言直接相关。比如，Java 最常用的单元测试框架是 Junit 和 TestNG；C/C++ 最常用的单元测试框架是 CppTest 和 Parasoft C/C++test；框架选型完成后，你还需要对桩代码框架和 Mock 代码框架选型，选型的主要依据是开发所采用的具体技术栈。
通常，单元测试框架、桩代码 /Mock 代码的选型工作由开发架构师和测试架构师共同决定。

为了能够衡量单元测试的代码覆盖率，通常你还需要引入计算代码覆盖率的工具。不同的语言会有不同的代码覆盖率统计工具，比如 Java 的 JaCoCo，JavaScript 的 Istanbul。在后续的文章中，我还会详细为你介绍代码覆盖率的内容。


最后你需要把单元测试执行、代码覆盖率统计和持续集成流水线做集成，以确保每次代码递交，都会自动触发单元测试，并在单元测试执行过程中自动统计代码覆盖率，最后以“单元测试通过率”和“代码覆盖率”为标准来决定本次代码递交是否能够被接受。



## 04 | 什么自动化测试


> 什么是自动化测试？

> 自动化测试的本质是先写一段代码，然后去测试另一段代码，所以实现自动化测试用例本身属于开发工作，需要投入大量的时间和精力，并且已经开发完成的用例还必须随着被测对象的改变而不断更新，你还需要为此付出维护测试用例的成本。

> 什么样的项目适合自动化测试？

第一，需求稳定，不会频繁变更。
第二，研发和维护周期长，需要频繁执行回归测试。
第三，需要在多种平台上重复运行相同测试的场景。
比较稳定的软件功能进行自动化测试，对变动较大或者需求暂时不明确的功能进行手工测试，最终目标是用 20% 的精力去覆盖 80% 的回归测试。

## 05 | 软件开发各阶段都有哪些自动化测试技术

#### 单元测试的自动化技术

首先，你可能认为单元测试本身就是自动化的，因为它根据软件详细设计采用等价类划分和边界值分析方法设计测试用例，在测试代码实现后再以自动化的方式统一执行。
这个观点非常正确，但这仅仅是一部分，并没有完整地描述单元测试“自动化”的内涵。从广义上讲，单元测试阶段的“自动化”内涵不仅仅指测试用例执行的自动化，还应该包含以下五个方面：
用例框架代码生成的自动化；
部分测试输入数据的自动化生成；
自动桩代码的生成；
被测代码的自动化静态分析；
测试覆盖率的自动统计与分析。
你可能感觉这些内容有些陌生，不过没关系，下面我就详细地跟你说说每一条的具体含义。


用例框架代码生成的自动化: 通常来说，你可以使用测试框架（例如 Go 的标准 testing 包）来编写测试用例。

```go
func TestAdd(t *testing.T) {
    result := Add(2, 3)
    if result != 5 {
        t.Errorf("Expected 5, got %d", result)
    }
}
```
部分测试输入数据的自动化生成: 你可以编写代码来自动生成测试数据。

```go
func TestAddWithRandomData(t *testing.T) {
    for i := 0; i < 10; i++ {
        a, b := rand.Intn(100), rand.Intn(100)
        result := Add(a, b)
        if result != a+b {
            t.Errorf("For %d and %d, expected %d, got %d", a, b, a+b, result)
        }
    }
}
```
自动桩代码的生成: 有时，你可能需要模拟外部依赖。在 Go 中，这通常通过接口和模拟（mock）对象来完成。

```go
type DatabaseMock struct{}
func (db *DatabaseMock) Save(data string) error {
    // Mock implementation here
    return nil
}
```
被测代码的自动化静态分析: 可以使用工具如 golint 或 go vet 来进行代码静态分析。

```shell
go vet ./...
golint ./...
```
测试覆盖率的自动统计与分析: Go 语言的测试工具允许你收集测试覆盖率。

```shell
go test -cover ./...
```
go vet 常见警告

锁复制警告:

不要直接复制含有 sync.Mutex 或 sync.Map 的结构体。
而是应该使用指针或特定方法来共享这样的结构体。
```go
// 不好的做法
newMap := oldMap // 这里复制了锁

// 好的做法
newMap := &oldMap // 使用指针
```
结构体字面量警告: 使用键化（keyed）的字段来初始化结构体。

```go
// 不好的做法
x := MyStruct{"value1", "value2"}

// 好的做法
x := MyStruct{Field1: "value1", Field2: "value2"}
```

#### 集成测试的自动化技术

代码级集成测试和单元测试非常相似，它们都是对被测试函数以不同的输入参数组合进行调用并验证结果，只不过代码级集成测试的关注点，更多的是软件模块之间的接口调用和数据传递

代码级集成测试与单元测试最大的区别只是，代码级集成测试中被测函数内部调用的其他函数必须是真实的，不允许使用桩代码代替，而单元测试中允许使用桩代码来模拟内部调用的其他函数。


#### Web Service 测试的自动化技术


对于基于代码的 API 测试用例，通常包含三大步骤：
准备 API 调用时需要的测试数据；
准备 API 的调用参数并发起 API 的调用；
验证 API 调用的返回结果。


同样地，Web Service 测试“自动化”的内涵不仅仅包括 API 测试用例执行的自动化，还包括以下四个方面：
测试脚手架代码的自动化生成；
部分测试输入数据的自动生成；
Response 验证的自动化；
基于 SoapUI 或者 Postman 的自动化脚本生成。



理解 Web Service 测试自动化的多个方面确实需要一些实际代码来进一步解释。由于问题涉及多个部分，我将用 Go 语言针对其中几个关键点给出简单的示例。

测试脚手架代码的自动化生成
在 Go 语言中，你可以使用现有的测试框架如 testing 包来简化测试脚手架的创建。

```go

import (
    "net/http"
    "testing"
)

func TestAPICall(t *testing.T) {
    // 调用 API
    resp, err := http.Get("http://example.com/api/resource")
    if err != nil {
        t.Fatalf("API 请求失败: %v", err)
    }
    defer resp.Body.Close()

    // TODO: Response 验证的空实现
}
```

部分测试输入数据的自动生成
Go 的 testing 包允许你使用表格驱动的测试，这里可以加入自动生成的输入数据。

```go
func TestAPICallWithData(t *testing.T) {
    testCases := []struct {
        input  string
        output string
    }{
        // 自动生成的测试数据
    }

    for _, tc := range testCases {
        // 调用 API 并验证输出
    }
}
```

Response 验证的自动化
假设你有一个函数 validateResponse 来自动比较 Response。

```go
func validateResponse(t *testing.T, resp *http.Response) {
    // 自动化验证状态码、结构和字段
}
```

从 Postman 的 JSON 输出生成 Go 测试代码是一个多步骤过程。下面是一个概念性的步骤列表，以及一个简单的 Go 示例，展示如何从一个假定的 Postman JSON 格式开始。

步骤:
读取 Postman 导出的 JSON 文件。
解析 JSON 文件以获取 API 测试用例的详细信息，如请求类型、URL、请求头、请求体等。
使用这些信息生成 Go 语言测试代码。
Go 代码示例
这个示例只是一个非常简化的版本，用于演示核心概念。

假设我们有一个简单的 Postman JSON 输出，其中只有一个 GET 请求。

```json
{
    "info": {
        "_postman_id": "some_id",
        "name": "Sample Postman Collection"
    },
    "item": [
        {
            "name": "Get Resource",
            "request": {
                "method": "GET",
                "url": "http://example.com/api/resource"
            }
        }
    ]
}
```
Go 代码示例：

```go
package main

import (
	"encoding/json"
	"fmt"
	"io/ioutil"
	"os"
)

type PostmanCollection struct {
	Info struct {
		PostmanID string `json:"_postman_id"`
		Name      string `json:"name"`
	} `json:"info"`
	Item []struct {
		Name    string `json:"name"`
		Request struct {
			Method string `json:"method"`
			URL    string `json:"url"`
		} `json:"request"`
	} `json:"item"`
}

func main() {
	// 1. 读取 Postman 导出的 JSON 文件
	data, err := ioutil.ReadFile("postman_collection.json")
	if err != nil {
		fmt.Println("Error reading file:", err)
		return
	}

	// 2. 解析 JSON 文件
	var collection PostmanCollection
	if err := json.Unmarshal(data, &collection); err != nil {
		fmt.Println("Error unmarshalling JSON:", err)
		return
	}

	// 3. 生成 Go 测试代码
	for _, item := range collection.Item {
		fmt.Printf("func Test%s(t *testing.T) {\n", item.Name)
		fmt.Printf("\tresp, err := http.%s(\"%s\")\n", item.Request.Method, item.Request.URL)
		fmt.Println("\tif err != nil {")
		fmt.Println("\t\tt.Fatalf(\"API request failed: %v\", err)")
		fmt.Println("\t}")
		fmt.Println("\tdefer resp.Body.Close()")
		fmt.Println("\t// TODO: Add response validation")
		fmt.Println("}\n")
	}

	// 你可以将生成的代码保存到一个 .go 文件中，然后在项目中使用。
}
```
这个例子相当基础，但它展示了如何从 Postman 的 JSON 输出生成 Go 语言测试代码的基本思路。你可以根据需要扩展这个示例，以处理更多的 HTTP 方法、请求头、请求体等。


## 06 | 测试覆盖率

测试覆盖率通常被用来衡量测试的充分性和完整性，从广义的角度来讲，测试覆盖率主要分为两大类，一类是面向项目的需求覆盖率，另一类是更偏向技术的代码覆盖率。


需求覆盖率
需求覆盖率是指测试对需求的覆盖程度，通常的做法是将每一条分解后的软件需求和对应的测试建立一对多的映射关系，最终目标是保证测试可以覆盖每个需求，以保证软件产品的质量。

代码覆盖率
简单来说，代码覆盖率是指，至少被执行了一次的条目数占整个条目数的百分比。


代码覆盖率工具的实现原理


生成覆盖率文件
运行 go test 命令并附加 -coverprofile 参数：

```bash
go test ./... -coverprofile=coverage.out
```
这将会运行所有测试，并将覆盖率数据保存在 coverage.out 文件中。

查看覆盖率报告
使用 go tool cover 命令来查看覆盖率报告：

```shell
go tool cover -func=coverage.out
```
这将输出每个函数的覆盖率。

生成覆盖率 HTML 报告
你还可以生成一个 HTML 报告，该报告以可视化的方式显示哪些行被覆盖了：

```shell
go tool cover -html=coverage.out
```
这将打开一个浏览器窗口，显示覆盖率数据。

这些只是基本用法。你还可以通过其他标志和工具进行更为复杂的覆盖率分析。比如，有第三方工具和服务（如 Codecov、Coveralls 等）能帮助你更深入地分析覆盖率数据。

这些工具通常用于持续集成（CI）流程中，以自动化的方式持续跟踪代码覆盖率的变化。


#### 本地安装codecov 进行代码分析

```shell
pip install codecov
```

在 Go 语言中，go test 命令用于运行测试，并且它支持生成代码覆盖率报告。go test 命令的 -cover 选项可以用于启用覆盖率收集。Go 的测试工具背后使用了几个关键技术来实现代码覆盖率收集：

源代码插桩
Go 的测试工具会对源代码进行插桩（Instrumentation），即在源代码中自动插入一些额外的代码行以跟踪哪些代码路径被执行过。例如，通过添加计数器或者布尔标志。

运行时数据收集
当插桩后的代码被执行时，这些额外添加的代码行会收集数据，比如哪些函数被调用了，哪些分支被执行了等。

数据分析与报告
执行完测试后，收集到的覆盖率数据通常会保存到一个文件中（例如，.out 文件）。然后，这个文件可以被进一步分析以生成覆盖率报告。报告一般会以百分比的形式表示被测试代码覆盖的程度。

可视化
除了数字报告，一些工具还提供代码覆盖的可视化，这通常会在源代码旁边用颜色标记出哪些代码被执行过，哪些没有。

这就是 Go 代码覆盖率工具大致的工作原理。它们通过源代码插桩，运行时数据收集，以及后处理分析来提供代码覆盖率信息。



一个简单的例子来模拟源代码插桩和运行时数据收集的过程：

原始代码
假设我们有一个简单的函数，用于判断一个数是否为偶数：

```go
func IsEven(n int) bool {
    return n % 2 == 0
}
```
插桩后的代码
插桩后，我们可能会在函数内部添加一些额外的代码来收集数据。例如，添加一个计数器：

```go
var IsEvenCalled int = 0  // 计数器，记录 IsEven 函数被调用的次数
var EvenCount int = 0     // 计数器，记录返回 true 的次数
var OddCount int = 0      // 计数器，记录返回 false 的次数

func IsEven(n int) bool {
    IsEvenCalled++  // 每次调用 IsEven 函数，计数器加 1

    result := n % 2 == 0
    if result {
        EvenCount++  // 如果是偶数，EvenCount 计数器加 1
    } else {
        OddCount++   // 如果是奇数，OddCount 计数器加 1
    }

    return result
}
```
运行时数据收集
当你调用 IsEven 函数时，计数器会更新：

```go
func main() {
    fmt.Println(IsEven(2))  // 输出：true
    fmt.Println(IsEven(3))  // 输出：false

    // 输出调用统计
    fmt.Println("IsEvenCalled:", IsEvenCalled)  // 输出：2
    fmt.Println("EvenCount:", EvenCount)        // 输出：1
    fmt.Println("OddCount:", OddCount)          // 输出：1
}
```
这样，我们就能够知道 IsEven 函数被调用了多少次，以及它返回了多少次 true 或 false。


用 Go 代码来模拟 Java 的 On-The-Fly 和 Offline 插桩模式可能有些不太直接，因为 Go 和 Java 在这方面有根本的不同。

On-The-Fly 模式
这个模式通常是在运行时动态地修改或注入代码。在 Java 中，这通常是通过 Java Agent 和类装载器实现的。Go 语言没有内置的动态代码修改机制，但可以通过一些设计模式或库来模拟。

```go
type Instrument interface {
    Execute() bool
}

type OriginalCode struct{}

func (o *OriginalCode) Execute() bool {
    // 原始代码逻辑
    return true
}

type OnTheFlyInstrumented struct {
    Original Instrument
}

func (o *OnTheFlyInstrumented) Execute() bool {
    // 插桩代码
    fmt.Println("On-The-Fly: Before execute")
    result := o.Original.Execute()
    fmt.Println("On-The-Fly: After execute")
    return result
}
```
使用：

```go
func main() {
    original := &OriginalCode{}
    instrumented := &OnTheFlyInstrumented{Original: original}
    instrumented.Execute()
}
```
Offline 模式
这个模式通常是在编译阶段或者测试之前进行代码注入或修改。

你可以先生成一个被修改过的 .go 文件或直接修改原始 .go 文件，然后再编译它。

例如，原始代码文件 original.go：

```go
func Execute() bool {
    return true
}
```
修改为 offline_instrumented.go：

```go
func Execute() bool {
    // 插桩代码
    fmt.Println("Offline: Before execute")
    result := true // 原始代码逻辑
    fmt.Println("Offline: After execute")
    return result
}
```
然后使用这个新版本的 offline_instrumented.go 进行编译和测试。

这两个例子都是简化的，但希望能帮助你理解 On-The-Fly 和 Offline 插桩模式的基本概念。在实际应用中，这些任务通常由专门的工具和库来完成。


## 07 | 软件缺陷报告？


#### 缺陷概述:

缺陷概述通常会提供更多概括性的缺陷本质与现象的描述，是缺陷标题的细化。


#### 缺陷影响:

缺陷影响决定了缺陷的优先级（Priority）和严重程度（Severity），开发经理会以此为依据来决定修复该缺陷的优先级；而产品经理会以此为依据来衡量缺陷的严重程度，并决定是否要等该缺陷被修复后才能发布产品。


#### 环境配置
环境配置用以详细描述测试环境的配置细节，为缺陷的重现提供必要的环境信息

#### 前置条件
前置条件是指测试步骤开始前系统应该处在的状态，其目的是减少缺陷重现步骤的描述。合理地使用前置条件可以在描述缺陷重现步骤时排除不必要的干扰，使其更有针对性。


#### 缺陷重现

操作步骤通常是从用户角度出发来描述的，每个步骤都应该是可操作并且是连贯的，所以往往会采用步骤列表的表现形式。


#### 期望结果和实际结果

期望结果和实际结果通常和缺陷重现步骤绑定在一起，在描述重现步骤的过程中，需要明确说明期待结果和实际结果。期待结果来自于对需求的理解，而实际结果来自于测试执行的结果。


#### 根原因分析（Root Cause Analysis）

根原因分析就是我们平时常说的 RCA，如果你能在发现缺陷的同时，定位出问题的根本原因，清楚地描述缺陷产生的原因并反馈给开发工程师，那么开发工程师修复缺陷的效率就会大幅提升，而且你的技术影响力也会被开发认可。


## 08 | 测试计划？


#### 测试策略?



#### 功能测试

应用场景：
验证软件的特定功能是否符合需求。

独特的测试方法：
单元测试：针对代码的最小可测试单元。
黑盒测试：不关注内部结构，只测试功能。

重点关注要点：
边界条件
数据有效性
错误和异常处理

具体举例：
对输入框进行空值、超长值、特殊字符输入测试。

#### 兼容性测试

应用场景：
在不同硬件、操作系统、数据库、浏览器环境下验证软件。

独特的测试方法：
跨浏览器测试。
跨平台测试。

重点关注要点：
不同操作系统
浏览器版本
屏幕尺寸

具体举例：
在Windows和MacOS上运行软件并对比结果。

#### 性能测试

应用场景：
验证软件在高负载下的响应时间和稳定性。

独特的测试方法：
压力测试：模拟超出正常运行条件的场景。
负载测试：模拟正常或峰值负载的场景。

重点关注要点：
响应时间
系统吞吐量
资源利用率

具体举例：
用1000个并发用户访问网站，观察响应时间。

#### 接口测试

应用场景：
验证系统组件间的数据交换是否正确。

独特的测试方法：
REST/SOAP API测试。
数据库接口测试。

重点关注要点：
数据格式
请求和响应时间
错误码处理


具体举例：
发送一个无效的JSON请求到API，检查是否返回适当的错误码。


#### 集成测试

应用场景：
验证不同模块或服务组合后的整体工作性。

独特的测试方法：
顶部下行或底部上行逐步集成。
大批量集成。

重点关注要点：
数据流
功能交互
性能影响

具体举例：
在一个电商应用中，确保购物车和支付模块正确集成。

#### 安全测试

应用场景：
验证软件对于各种攻击的抵抗能力。

独特的测试方法：
SQL注入。
跨站脚本（XSS）。

重点关注要点：
认证和授权
数据加密
注入攻击

具体举例：
尝试在没有登录的情况下访问一个需要授权的页面。

#### 容量验证

应用场景：
确保软件能在预期的规模和大小下正常运行。

独特的测试方法：
数据量测试。
用户并发量测试。

重点关注要点：
系统扩展性
数据库容量
网络带宽

具体举例：
测试当数据库存储达到90%时系统的行为。

#### 安装测试

应用场景：
验证软件安装和卸载过程的正确性。

独特的测试方法：
完全安装/卸载。
自定义安装。

重点关注要点：
安装时间
初始设置
卸载残留

具体举例：
验证软件在不同磁盘空间下能否成功安装。

#### 故障恢复测试

应用场景：
验证系统在发生故障后能否成功恢复。

独特的测试方法：
强制重启。
数据库故障模拟。
每种测试类型都有其特

重点关注要点：
数据恢复
系统日志
通知和警告

具体举例：
故意关闭数据库服务，看是否能自动恢复并发送警告邮件。

#### 举例

比如，对用户登录模块来讲，“用户无法正常登录”和“用户无法重置密码”这两个潜在问题，对业务的影响孰轻孰重一目了然，所以，你应该按照优先级来先测“用户正常登录”，再测“用户重置密码”。

测试策略还需要说明，采用什么样的测试类型和测试方法。 这里需要注意的是，不仅要给出为什么要选用这个测试类型，还要详细说明具体的实施方法。

第一，功能测试
对于功能测试，你应该根据测试需求分析的思维导图来设计测试用例。
主线业务的功能测试由于经常需要执行回归测试，所以你需要考虑实施自动化测试，并且根据项目技术栈和测试团队成员的习惯与能力来选择合适的自动化测试框架。
这里需要注意的是，你通常应该先实现主干业务流程的测试自动化。
实际操作时，你通常需要先列出主要的功能测试点，并决定哪些测试点适合采用自动化测试，并且决定具体使用什么样的框架和技术。
对于需要手工测试的测试点，你要决定采用什么类型的测试用例设计方法，以及如何准备相关的测试数据。
另外，你还要评估被测软件的可测试性，如果有可测试性的问题，需要提前考虑切实可行的变通方案，甚至要求开发人员提供可测试性的接口。

第二，兼容性测试
对于兼容性测试来说，Web 测试需要确定覆盖的浏览器类型和版本，移动设备测试需要确定覆盖的设备类型和具体 iOS/Android 的版本等。
你可能会问，我要怎么确定需要覆盖的移动设备类型以及 iOS/Android 的版本列表呢？这个问题其实并不难：
如果是既有产品，你可以通过大数据技术分析产品的历史数据得出 Top 30% 的移动设备以及 iOS/Android 的版本列表，那么兼容性测试只需覆盖这部分即可。
如果是一个全新的产品，你可以通过 TalkingData 这样的网站来查看目前主流的移动设备，分辨率大小、iOS/Android 版本等信息来确定测试范围。
兼容性测试的实施，往往是在功能测试的后期，也就是说需要等功能基本都稳定了，才会开始兼容性测试。
当然也有特例，比如，对于前端引入了新的前端框架或者组件库，往往就会先在前期做兼容性评估，以确保不会引入后期无法解决的兼容性问题。
兼容性测试用例的选取，往往来自于已经实现的自动化测试用例。道理很简单，因为兼容性测试往往要覆盖最常用的业务场景，而这些最常用的业务场景通常也是首批实现自动化测试的目标。
所以，我们的 GUI 自动化框架，就需要能够支持同一套测试脚本在不做修改的前提下，运行于不同的浏览器。

第三，性能测试
对于性能测试，需要在明确了性能需求（并发用户数、响应时间、事务吞吐量等）的前提下，结合被测系统的特点，设计性能测试场景并确定性能测试框架。
比如，是直接在 API 级别发起压力测试，还是必须模拟终端用户行为进行基于协议的压力测试。再比如，是基于模块进行压力测试，还是发起全链路压测。
如果性能是背景数据敏感的场景，还需要确定背景数据量级与分布，并决定产生背景数据的技术方案，比如是通过 API 并发调用来产生测试数据，还是直接在数据库上做批量 insert 和 update 操作，或者是两种方式的结合。
最后，无论采用哪种方式，都需要明确待开发的单用户脚本的数量，以便后续能够顺利组装压测测试场景。
性能测试的实施，是一个比较复杂的问题。首先，需要根据你想要解决的问题，确定性能测试的类型；然后，根据具体的性能测试类型开展测试。
性能测试的实施，往往先要根据业务场景来决定需要开发哪些单用户脚本，脚本的开发会涉及到很多性能测试脚本特有的概念，比如思考时间、集合点、动态关联等等。



## 09 | 软件测试工程师的核心竞争力


> 作为测试人员，必须要深入理解业务，但是业务知识不能等同于测试能力。

> 测试开发岗位的核心其实是“测试”，“开发”的目的是更好地服务于测试，我们看重的是对测试的理解，以及在此基础上设计、开发帮助测试人员提高效率并解决实际问题的工具，而不是一个按部就班、纯粹意义上的开发人员。


> 目前的测试工程师分为两大类别，一类是做业务功能测试的，另一类是做测试开发的，二者的核心竞争力有很大差别。


#### 传统测试工程师应该具备的核心竞争力


测试策略设计能力、测试用例设计能力、快速学习能力、探索性测试思维、缺陷分析能力、自动化测试技术和良好的沟通能力。


#### 测试策略设计能力

测试策略设计能力是指，对于各种不同的被测软件，能够快速准确地理解需求，并在有限的时间和资源下，明确测试重点以及最适合的测试方法的能力。

测试要具体执行到什么程度？
测试需要借助于什么工具？
如何运用自动化测试以及自动化测试框架，以及如何选型？
测试人员资源如何合理分配？
测试进度如何安排？
测试风险如何应对？



#### 测试用例设计能力

要做好测试用例设计，不仅需要深入理解被测软件的业务需求和目标用户的使用习惯，还要熟悉软件的具体设计和运行环境，包括技术架构、缓存机制、中间件技术、第三方服务集成等等。

平时就要多积累，对常见的缺陷模式、典型的错误类型以及遇到过的缺陷，要不断地总结、归纳，才能逐渐形成体系化的用例设计思维。


#### 快速学习能力


对不同业务需求和功能的快速学习与理解能力；
对于测试新技术和新方法的学习与应用能力。

比如，当你学习一个新的开源工具时，建议你直接看官方文档：一来，这里的内容是最新而且是最权威的；二来，可以避免网上信息质量的参差不齐。知识输入源头是单一，而且权威的话，你的学习曲线也必然会比较平滑。
另外，当学习新内容时，你一定要做到理解其原理，而不是只停留在表面的、简单的操作和使用，长期保持这种学习状态，可以在很大程度上提高逻辑思维和理解能力。这样，当你再面对其他新鲜事物时候，也会更容易理解，形成良性循环。


#### 探索性测试思维

优秀的探索性测试思维可以帮助你实现低成本的“精准测试”，精准测试最通俗的理解可以概括为针对开发代码的变更，目标明确并且有针对性地对变更点以及变更关联点做测试，这也是目前敏捷测试主推的测试实践之一。


#### 缺陷分析能力

缺陷分析能力，通常包含三个层面的含义：

> 对于已经发现的缺陷，结合发生错误的上下文以及后台日志，可以预测或者定位缺陷的发生原因，甚至可以明确指出具体出错的代码行，由此可以大幅缩短缺陷的修复周期，并提高开发工程师对于测试工程师的认可以及信任度；

> 根据已经发现的缺陷，结合探索性测试思维，推断同类缺陷存在的可能性，并由此找出所有相关的潜在缺陷；

> 可以对一段时间内所发生的缺陷类型和趋势进行合理分析，由点到面预估整体质量的健康状态，并能够对高频缺陷类型提供系统性的发现和预防措施，并以此来调整后续的测试策略。


#### 自动化测试技术

一方面，自动化测试技术本身不绑定被测对象，比如说你掌握了 GUI 的自动化测试技术，那么你就可以基于这个技术去做任何 GUI 系统的界面功能测试了。

#### 良好的沟通能力

一方面，你需要对接产品经理和项目经理，以确保需求的正确实现和项目整体质量的达标；
另一方面，你还要和开发人员不断地沟通、协调，确保缺陷的及时修复与验证。



#### 测试开发工程师的核心竞争力

第一项核心竞争力，测试系统需求分析能力
第二项核心竞争力，更宽广的知识体系
测试开发工程师需要具备非常宽广的知识体系，你不仅需要和传统的测试开发工程师打交道，因为他们是你构建的测试工具或者平台的用户；而且还要和 CI/CD、和运维工程师们有紧密的联系，因为你构建的测试工具或者平台，需要接入到 CI/CD 的流水线以及运维的监控系统中去


## 10 | 软件测试工程师需要掌握的非测试知识有哪些？


> 开发工程师通常是“深度遍历”，关注的是“点”；而测试工程师通常是“广度遍历”，关注的是“面”。需要了解掌握的非测试知识实在是太多了，这简直就是一个 mini 版的系统架构师！


小到 Linux/Unix/Windows 操作系统的基础知识，Oracle/MySQL 等传统关系型数据库技术，NoSQL 非关系型数据库技术，中间件技术，Shell/Python 脚本开发，版本管理工具与策略，CI/CD 流水线设计，F5 负载均衡技术，Fiddler/Wireshark/Tcpdump 等抓包工具，浏览器 Developer Tool 等；


大到网站架构设计，容器技术，微服务架构，服务网格（Service Mesh），DevOps，云计算，大数据，人工智能和区块链技术等。


网站架构的核心知识:

要做好互联网产品功能测试以外的其他测试，比如性能测试、稳定性测试、全链路压测、故障切换（Failover）测试、动态集群容量伸缩测试、服务降级测试和安全渗透测试等



#### 性能测试

应用场景：
电商网站的大促活动

独特的测试方法：
负载测试，压力测试

重点关注要点：
响应时间，系统吞吐量

具体举例：
使用JMeter模拟1000个用户并发访问，检查系统响应时间。

#### 稳定性测试

应用场景：
长时间运行的服务器应用

独特的测试方法：
耐久测试

重点关注要点：
内存泄漏，CPU使用

具体举例：
运行应用一周时间，检查内存和CPU使用情况。

#### 全链路压测

应用场景：
微服务架构中的数据流

独特的测试方法：
端到端的压力测试

重点关注要点：
微服务间的数据传输，数据库读写

具体举例：
模拟用户从登陆到下单的全过程，观察各个服务的性能。

#### 故障切换（Failover）测试

应用场景：
高可用系统

独特的测试方法：
主动关闭某个节点

重点关注要点：
数据一致性，恢复时间

具体举例：
在主数据库关闭的情况下，检查备份数据库是否能立即接管。

#### 动态集群容量伸缩测试

应用场景：
容器化应用，云服务

独特的测试方法：
动态增减节点

重点关注要点：
系统扩展性，数据一致性

具体举例：
在Kubernetes集群中，动态添加或删除Pod，观察集群性能。

#### 服务降级测试

应用场景：
电商秒杀活动

独特的测试方法：
限流，降级非核心服务

重点关注要点：
用户体验，核心功能可用性

具体举例：
在高流量期间，关闭商品推荐功能，观察核心购买流程是否流畅。

#### 安全渗透测试

应用场景：
任何涉及用户数据的应用

独特的测试方法：
黑盒测试，白盒测试

重点关注要点：
数据加密，注入攻击

具体举例：
尝试使用SQL注入攻击登录到系统。


比如，如果你不清楚 Memcached 这类分布式缓存集群的应用场景和基本原理，如果你不清楚缓存击穿、缓存雪崩、缓存预热、缓存集群扩容局限性等问题，你就设计不出针对缓存系统特有问题的测试用例；
再比如，如果你对网站的可伸缩性架构设计不了解，不清楚应用服务器的各种负载均衡实现的基本原理，不了解数据库的读写分离技术，你就无法完成诸如故障切换、动态集群容量伸缩、服务降级等相关的测试，同时对于性能测试和全链路压测过程中可能遇到的各种瓶颈，也会很难定位和调整。


#### 容器技术

很多中大型互联网企业都在推行容器化开发与运维，开发人员递交给测试工程师的软件版本通常就是一个 Docker Image，直接在容器上进行测试。有些公司还会把测试用例和执行框架也打包成 Docker Image，配合版本管理机制，实现用容器测试容器。


#### 云计算技术

前段时间，eBay 的一些产品线就对外宣布了和 Pivotal Cloud Foundry 的合作，会将部分产品线迁移到云端。显然，作为测试工程师，你必须理解服务在云端部署的技术细节才能更好的完成测试任务。

另一方面，测试基础服务作为提供测试服务的基础设施，比如测试执行环境服务（Test Execution Service）和测试数据准备服务（Test Data Service）等，也在逐渐走向云端。 比如，国外非常流行的 Sauce Labs，就是一个著名的测试执行环境公有云服务。

## 11 | 互联网产品的测试策略应该如何设计？

传统软件通常采用金字塔模型的测试策略，而现今的互联网产品往往采用菱形模型。菱形模型有以下四个关键点：

以中间层的 API 测试为重点做全面的测试。
轻量级的 GUI 测试，只覆盖最核心直接影响主营业务流程的 E2E 场景。
最上层的 GUI 测试通常利用探索式测试思维，以人工测试的方式发现尽可能多的潜在问题。
单元测试采用“分而治之”的思想，只对那些相对稳定并且核心的服务和模块开展全面的单元测试，而应用层或者上层业务只会做少量的单元测试。



## Goconv

```go
package tempe

import (
	"testing"

	. "github.com/smartystreets/goconvey/convey"
)

func TestAdd(t *testing.T) {
	Convey("将两数相加", t, func() {
		So(Add(1, 2), ShouldEqual, 3)
	})
}

func TestSubtract(t *testing.T) {
	Convey("将两数相减", t, func() {
		So(Subtract(1, 2), ShouldEqual, -1)
	})
}

func TestMultiply(t *testing.T) {
	Convey("将两数相乘", t, func() {
		So(Multiply(3, 2), ShouldEqual, 6)
	})
}

func TestDivision(t *testing.T) {
	Convey("将两数相除", t, func() {

		Convey("除以非 0 数", func() {
			num, err := Division(10, 2)
			So(err, ShouldBeNil)
			So(num, ShouldEqual, 5)
		})

		Convey("除以 0", func() {
			_, err := Division(10, 0)
			So(err, ShouldNotBeNil)
		})
	})
}

```

```go
package tempe

import (
	"errors"
)

func Add(a, b int) int {
	return a + b
}

func Subtract(a, b int) int {
	return a - b
}

func Multiply(a, b int) int {
	return a * b
}

func Division(a, b int) (int, error) {
	if b == 0 {
		return 0, errors.New("被除数不能为 0")
	}
	return a / b, nil
}

```

安装：
```shell
$ go install github.com/smartystreets/goconvey
```

运行：
```shell
$GOPATH/bin/goconvey
```

