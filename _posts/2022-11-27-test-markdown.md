---
layout: post
title: 人工智能？
subtitle:
tags: [Artificial Intelligence AI]
---

# 专业英语

Artificial Intelligence (AI) is the mantra of the current era. The phrase is intoned by technologists, academicians, journalists and venture capitalists alike. As with many phrases that cross over from technical academic fields into general circulation, there is significant misunderstanding accompanying the use of the phrase. The idea that our era is somehow seeing the emergence of an intelligence in silicon that rivals our own entertains all of us — enthralling us and frightening us in equal measure.

人工智能 (AI) 是当今时代的口头禅。这句话被技术专家、学者、记者和风险投资家等所引用。与许多从技术学术领域跨入一般流通的短语一样，该短语的使用也存在重大误解。我们的时代正在以某种方式见证硅智能的出现，可以与我们自己的智能相媲美，这一想法让我们所有人都很开心——既让我们着迷，也让我们同样害怕。

Whether or not we come to understand “intelligence” any time soon, we do have a major challenge on our hands in bringing together computers and humans in ways that enhance human life. humans are proceeding with the building of societal-scale, inference-and-decision-making systems that involve machines, humans and the environment.

无论我们是否很快就会理解“智能”，我们确实面临着以改善人类生活的方式将计算机和人类结合在一起的重大挑战。人类正在着手构建涉及机器、人类和环境的社会规模推理和决策系统。

Let us begin by considering more carefully what “AI” has been used to refer to, both recently and historically.

让我们首先更仔细地考虑一下最近和历史上“人工智能”所指的是什么。

Most of what is being called “AI” today, particularly in the public sphere, is what has been called “Machine Learning” (ML) for the past several decades. ML is an algorithmic field that blends ideas from statistics, computer science and many other disciplines (see below) to design algorithms that process data, make predictions and help make decisions. In terms of impact on the real world, ML is the real thing, and not just recently. Indeed, that ML would grow into massive industrial relevance was already clear in the early 1990s, and by the turn of the century forward-looking companies such as Amazon were already using ML throughout their business, solving mission-critical back-end problems in fraud detection and supply-chain prediction, and building innovative consumer-facing services such as recommendation systems. The phrase “Data Science” began to be used to refer to this phenomenon, reflecting the need of ML algorithms experts to partner with database and distributed-systems experts to build scalable, robust ML systems

今天，特别是在公共领域，大多数被称为“AI”的东西在过去几十年中一直被称为“机器学习”(ML)。ML 是一个算法领域，它融合了统计学、计算机科学和许多其他学科（见下文）的思想，以设计处理数据、进行预测和帮助做出决策的算法。就对现实世界的影响而言，ML 是真实的，而且不仅仅是最近。事实上，ML 将在 20 世纪 90 年代初期发展成为巨大的工业相关性，到世纪之交，亚马逊等具有前瞻性的公司已经在其整个业务中使用 ML，解决欺诈中的关键任务后端问题检测和供应链预测，以及构建面向消费者的创新服务，例如推荐系统。新的商业模式将会出现。“数据科学”一词开始被用来指代这种现象，反映了 ML 算法专家与数据库和分布式系统专家合作以构建可扩展、健壮的 ML 系统的需要

_This confluence of ideas and technology trends has been rebranded as “AI” over the past few years. This rebranding is worthy of some scrutiny._

_这种思想和技术趋势的融合在过去几年中被重新命名为“人工智能”。这种品牌重塑值得仔细研究。_

Historically, the phrase “AI” was coined in the late 1950’s to refer to the heady aspiration of realizing in software and hardware an entity possessing human-level intelligence. This was largely an academic enterprise. While related academic fields such as operations research, statistics, pattern recognition, information theory and control theory already existed, and were often inspired by human intelligence these fields were arguably focused on “low-level” signals and decisions.

从历史上看，“AI”一词是在 20 世纪 50 年代后期创造的，指的是在软件和硬件中实现拥有人类智能的实体的强烈愿望。这主要是一个学术事业。虽然运筹学、统计学、模式识别、信息论和控制论等相关学术领域已经存在，并且经常受到人类智能的启发，但这些领域可以说侧重于“低级”信号和决策。

Indeed, the famous “backpropagation” algorithm that was rediscovered by David Rumelhart in the early 1980s, and which is now viewed as being at the core of the so-called “AI revolution,” first arose in the field of control theory in the 1950s and 1960s. One of its early applications was to optimize the thrusts of the Apollo spaceships as they headed towards the moon.

事实上，David Rumelhart 在 80 年代初重新发现的著名“反向传播”算法，现在被视为所谓“人工智能革命”的核心，最早出现在 1950 年代的控制理论领域和 1960 年代。它的早期应用之一是优化阿波罗飞船驶向月球时的推力。

One could simply agree to refer to all of this as “AI,”

人们可以简单地同意将所有这些都称为“人工智能”

The past two decades have seen major progress — in industry and academia — in a complementary aspiration to human-imitative AI that is often referred to as “Intelligence Augmentation” (IA). Here computation and data are used to create services that augment human intelligence and creativity. A search engine can be viewed as an example of IA (it augments human memory and factual knowledge), as can natural language translation (it augments the ability of a human to communicate). Computing-based generation of sounds and images serves as a palette and creativity enhancer for artists. These services they mostly perform various kinds of string-matching and numerical operations

在过去的二十年里，工业界和学术界在对通常被称为“智能增强”(IA) 的仿人人工智能的互补愿望方面取得了重大进展。在这里，计算和数据用于创建增强人类智慧和创造力的服务。搜索引擎可以被视为 IA 的一个例子（它增强了人类的记忆和事实知识），自然语言翻译也是如此（它增强了人类交流的能力）。基于计算的声音和图像生成可作为艺术家的调色板和创造力增强器。这种服务它们主要执行各种字符串匹配和数字操作，以捕获人类可以利用的模式。

We’re all familiar with the term “Artificial Intelligence.” After all, it’s been a popular focus in movies such as The Terminator, The Matrix, and Ex Machina (a personal favorite of mine). But you may have recently been hearing about other terms like “Machine Learning” and “Deep Learning,” sometimes used interchangeably with artificial intelligence. As a result, the difference between artificial intelligence, machine learning, and deep learning can be very unclear.

我们都熟悉“人工智能”一词。毕竟，它一直是《终结者》、《黑客帝国》和《机械姬》（我个人最喜欢的一部）等电影中的热门焦点。但您最近可能听说过其他术语，例如“机器学习”和“深度学习”，有时可与人工智能互换使用。因此，人工智能、机器学习和深度学习之间的区别可能非常模糊。

I’ll begin by giving a quick explanation of what Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) actually mean and how they’re different. Then, I’ll share how AI and the Internet of Things are inextricably intertwined, with several technological advances all converging at once to set the foundation for an AI and IoT explosion.

我将首先快速解释人工智能 (AI)、机器学习 (ML) 和深度学习 (DL) 的实际含义以及它们之间的区别。然后，我将分享人工智能和物联网是如何密不可分地交织在一起的，几项技术进步同时融合在一起，为人工智能和物联网的爆炸式增长奠定了基础。

So what’s the difference between AI, ML, and DL?

First coined in 1956 by John McCarthy, **AI involves machines that can perform tasks that are characteristic of human intelligence**. While this is rather general, it includes things like planning, understanding language, recognizing objects and sounds, learning, and problem-solving.

We can put AI in two categories, general and narrow. General AI would have all of the characteristics of human intelligence, including the capacities mentioned above. Narrow AI exhibits some facet(s) of human intelligence, and can do that facet extremely well, but is lacking in other areas. A machine that’s great at recognizing images, but nothing else, would be an example of narrow AI.

人工智能于 1956 年首次由约翰·麦卡锡 (John McCarthy) 创造，**涉及可以执行人类智能特有任务的机器**。虽然这是相当笼统的，但它包括计划、理解语言、识别物体和声音、学习和解决问题等内容。

我们可以把人工智能分为两类，一般的和狭义的。通用人工智能将具有人类智能的所有特征，包括上述能力。狭义 AI 展示了人类智能的某些方面，并且可以在这方面做得非常好，但在其他领域却有所欠缺。一台擅长识别图像但仅此而已的机器将是狭义人工智能的一个例子。

At its core, **machine learning is simply a way of achieving AI.**

在其核心，**机器学习只是实现人工智能的一种方式。**

Arthur Samuel coined the phrase not too long after AI, in 1959, defining it as, “the ability to learn without being explicitly programmed.” You see, you can get AI **without** using machine learning, but this would require building millions of lines of codes with complex rules and decision-trees.

Arthur Samuel 在 AI 之后不久于 1959 年创造了这个词，将其定义为“无需明确编程即可学习的能力”。你看，你可以在**不**使用机器学习的情况下获得人工智能，但这需要构建数百万行具有复杂规则和决策树的代码。

So instead of hard-coding software routines with specific instructions to accomplish a particular task, machine learning is a way of “training” an algorithm so that it can **learn how**. “Training” involves feeding huge amounts of data to the algorithm and allowing the algorithm to adjust itself and improve.

因此，机器学习不是使用特定指令对软件例程进行硬编码来完成特定任务，而是一种“训练”算法的方式，以便它可以**学习如何**。“训练”涉及向算法提供大量数据并允许算法自我调整和改进。

To give an example, machine learning has been used to make drastic improvements to computer vision (the ability of a machine to recognize an object in an image or video). You gather hundreds of thousands or even millions of pictures and then have humans tag them. For example, the humans might tag pictures that have a cat in them versus those that do not. Then, the algorithm tries to build a model that can accurately tag a picture as containing a cat or not as well as a human. Once the accuracy level is high enough, the machine has now “learned” what a cat looks like.

举个例子，机器学习已被用于大幅改进计算机视觉（机器识别图像或视频中的对象的能力）。你收集了数十万甚至数百万张图片，然后让人类标记它们。例如，人类可能会标记有猫的图片和没有猫的图片。然后，该算法尝试建立一个模型，该模型可以准确地将图片标记为包含猫或不包含人。一旦准确度足够高，机器就可以“学习”猫的样子

**Deep learning is one of many approaches to machine learning**. Other approaches include decision tree learning, inductive logic programming, clustering, reinforcement learning, and Bayesian networks, among others.

**深度学习是机器学习的众多方法之一**。其他方法包括决策树学习、归纳逻辑编程、聚类、强化学习和贝叶斯网络等。

Deep learning was inspired by the structure and function of the brain, namely the interconnecting of many neurons. Artificial Neural Networks (ANNs) are algorithms that mimic the biological structure of the brain.

深度学习的灵感来自大脑的结构和功能，即许多神经元的相互连接。人工神经网络 (ANN) 是模拟大脑生物结构的算法。

In ANNs, there are “neurons” which have discrete layers and connections to other “neurons”. Each layer picks out a specific feature to learn, such as curves/edges in image recognition. It’s this layering that gives deep learning its name, depth is created by using multiple layers as opposed to a single layer

在 ANN 中，存在具有离散层和与其他“神经元”连接的“神经元”。每一层都挑选出一个特定的特征来学习，比如图像识别中的曲线/边缘。正是这种分层给了深度学习它的名字，深度是通过使用多层而不是单层创建的。

Unleashing Each Other’s Potential

释放彼此的潜能

The value and the promises of both AI and IoT are being realized because of the other.

AI 和 IoT 的价值和前景因对方而得以实现。

Machine learning and deep learning have led to huge leaps for AI in recent years. As mentioned above, machine learning and deep learning require massive amounts of data to work, and this data is being collected by the billions of sensors that are continuing to come online in the Internet of Things. **IoT makes better AI.**

近年来，机器学习和深度学习为人工智能带来了巨大飞跃。如上所述，机器学习和深度学习需要大量数据才能发挥作用，而这些数据由物联网中不断联机的数十亿个传感器收集。**物联网造就了更好的人工智能。**

Improving AI will also drive the adoption of the Internet of Things, creating a virtuous cycle in which both areas will accelerate drastically. That’s because **AI makes IoT useful.**

在工业方面，人工智能可用于预测机器何时需要维护或分析制造过程以大幅提高效率，从而节省数百万美元。

On the industrial side, AI can be applied to predict when machines will need maintenance or analyze manufacturing processes to make big efficiency gains, saving millions of dollars.

改进人工智能也将推动物联网的采用，创造一个良性循环，这两个领域都将大幅加速。那是因为**人工智能让物联网变得有用。**

On the consumer side, rather than having to adapt to technology, technology can adapt to us. Instead of clicking, typing, and searching, we can simply ask a machine for what we need. We might ask for information like the weather or for an action like preparing the house for bedtime (turning down the thermostat, locking the doors, turning off the lights, etc.).

在消费者方面，技术可以适应我们，而不是必须适应技术。我们可以简单地向机器询问我们需要什么，而不是点击、输入和搜索。我们可能会询问天气之类的信息，或者要求采取行动，例如准备就寝时间（调低恒温器、锁门、关灯等）。

Converging Technological Advancements Have Made this Possible

Shrinking computer chips and improved manufacturing techniques means cheaper, more powerful sensors.

缩小计算机芯片和改进制造技术意味着更便宜、更强大的传感器。

Quickly improving battery technology means those sensors can last for years without needing to be connected to a power source.

快速改进电池技术意味着这些传感器无需连接电源即可使用数年。

Wireless connectivity, driven by the advent of smartphones, means that data can be sent in high volume at cheap rates, allowing all those sensors to send data to the cloud.

智能手机的出现推动了无线连接，这意味着可以以低廉的价格大量发送数据，从而允许所有这些传感器将数据发送到云端。

And the birth of the cloud has allowed for virtually unlimited storage of that data and virtually infinite computational ability to process it.

云的诞生允许几乎无限地存储该数据和几乎无限的计算能力来处理它。

Of course, there are [one](https://iotforall.com/amazon-go-were-all-f-cked-e6fb885f94c4#.hwfbrwcxq) or [two](https://iotforall.com/if-you-think-your-job-is-safe-from-artificial-intelligence-youre-wrong-f2da6f82135e#.uojboeijx) concerns about the impact of AI on our society and our future. But as advancements and adoption of both AI and IoT continue to accelerate, one thing is certain; the impact is going to be

当然，对于人工智能对我们的社会和未来的影响，存在一[两个](https://iotforall.com/amazon-go-were-all-f-cked-e6fb885f94c4#.hwfbrwcxq)[担忧](https://iotforall.com/if-you-think-your-job-is-safe-from-artificial-intelligence-youre-wrong-f2da6f82135e#.uojboeijx)。但随着人工智能和物联网的进步和采用继续加速，有一件事是肯定的；影响将是深远的。

“The last 10 years have been about building a world that is mobile-first. In the next 10 years, we will shift to a world that is AI-first.” (Sundar Pichai, CEO of **Google**, October 2016)

> “过去 10 年一直致力于建设一个移动优先的世界。未来 10 年，我们将转向人工智能优先的世界。” （**谷歌**首席执行官 Sundar Pichai， 2016 年 10 月）

From Amazon and Facebook to Google and Microsoft, leaders of the world’s most influential technology firms are highlighting their enthusiasm for Artificial Intelligence (AI). But what is AI? Why is it important? And why now? While there is growing interest in AI, the field is understood mainly by specialists. Our goal for this primer is to make this important field accessible to a broader audience.

从亚马逊和 Facebook 到谷歌和微软，世界上最具影响力的科技公司的领导者都在强调他们对人工智能 (AI) 的热情。但什么是人工智能？它为什么如此重要？为什么是现在？尽管人们对 AI 越来越感兴趣，但该领域主要由专家了解。我们编写这本入门读物的目标是让更广泛的受众能够接触到这一重要领域。

We’ll begin by explaining the meaning of ‘AI’ and key terms including ‘machine learning’. We’ll illustrate how one of the most productive areas of AI, called ‘deep learning’, works. We’ll explore the problems that AI solves and why they matter.

我们将从解释“AI”的含义和包括“机器学习”在内的关键术语开始。我们将说明人工智能最有成效的领域之一，即“深度学习”，是如何工作的。我们将探讨 AI 解决的问题及其重要性。

What is AI?

什么是人工智能？

Artificial intelligence: The science of intelligent programs

人工智能：智能程序科学

Coined in 1956 by Dartmouth Assistant Professor John McCarthy, ‘Artificial Intelligence’ (AI) is a general term that refers to hardware or software that exhibits behaviour which appears intelligent. In the words of Professor McCarthy, it is “the science and engineering of making intelligent machines, especially intelligent computer programs.”

“人工智能”(AI) 由达特茅斯学院助理教授约翰·麦卡锡 (John McCarthy) 于 1956 年创造，是一个通用术语，指的是表现出智能行为的硬件或软件。用麦卡锡教授的话说，就是“制造智能机器，尤其是智能计算机程序的科学与工程”。

Basic ‘AI’ has existed for decades, via rules-based programs that deliver rudimentary displays of ‘intelligence’ in specific contexts. Progress, however, has been limited — because algorithms to tackle many real-world problems are too complex for people to program by hand.

基本的“人工智能”已经存在了几十年，通过基于规则的程序在特定环境中提供基本的“智能”显示。然而，进展是有限的——因为解决许多现实世界问题的算法对于人们手工编程来说太复杂了。

Complicated activities including making medical diagnoses, predicting when machines will fail or gauging the market value of certain assets, involve thousands of data sets and non-linear relationships between variables. In these cases, it’s difficult to use the data we have to best effect — to ‘**optimise’** our predictions. In other cases, including recognising objects in images and translating languages, we can’t even develop rules to describe the **features** we’re looking for. How can we write a set of rules, to work in all situations, that describe the appearance of a dog?

进行医疗诊断、预测机器何时会发生故障或评估某些资产的市场价值等复杂活动涉及数以千计的数据集和变量之间的非线性关系。在这些情况下，很难使用我们必须获得的数据来达到最佳效果——“**优化”**我们的预测。在其他情况下，包括识别图像中的对象和翻译语言，我们甚至无法制定规则来描述我们正在寻找的**特征。**我们如何编写一套适用于所有情况的规则来描述狗的外貌？

What if we could transfer the difficulty of making complex predictions — the **data optimisation** and **feature specification** — from the programmer to the program? This is the promise of modern artificial intelligence.

如果我们可以转移做出复杂预测的难度——**数据优化**和**特征说明**——从程序员到程序？这是现代人工智能的承诺。

Machine Learning: offloading optimisation

**Machine learning (ML)** is a sub-set of AI. All machine learning is AI, but not all AI is machine learning (Figure 1, above). Interest in ‘AI’ today reflects enthusiasm for machine learning, where advances are rapid and significant.

**机器学习 (ML)**是 AI 的一个子集。所有机器学习都是人工智能，但并非所有人工智能都是机器学习（上图 1）。今天对“人工智能”的兴趣反映了对机器学习的热情，机器学习的进步迅速而显着。

Machine learning lets us tackle problems that are too complex for humans to solve by shifting some of the burden to the algorithm. As AI pioneer Arthur Samuel wrote in 1959, machine learning is the ‘field of study that gives computers the ability to learn without being explicitly programmed.’

机器学习让我们通过将一些负担转移给算法来解决人类无法解决的复杂问题。正如人工智能先驱亚瑟·塞缪尔 (Arthur Samuel) 在 1959 年所写，机器学习是“让计算机无需明确编程即可学习的研究领域”。

The goal of most machine learning is to develop a prediction engine for a particular use case. An algorithm will receive information about a domain (say, the films a person has watched in the past) and weigh the inputs to make a useful prediction (the probability of the person enjoying a different film in the future). By giving ‘computers the ability to learn’, we mean passing the task of optimisation — of weighing the variables in the available data to make accurate predictions about the future — to the algorithm . Sometimes we can go further, offloading to the program the task of specifying the features to consider in the first place.

大多数机器学习的目标是为特定用例开发预测引擎。一种算法将接收有关某个领域的信息（例如，一个人过去看过的电影）并权衡输入以做出有用的预测（这个人将来喜欢不同电影的概率）。通过赋予“计算机学习能力”，我们的意思是将优化任务——权衡可用数据中的变量以对未来做出准确预测——传递给算法。有时我们可以走得更远，将首先指定要考虑的功能的任务卸载给程序。

Machine learning algorithms learn through training. An algorithm initially receives examples whose outputs are known, notes the difference between its predictions and the correct outputs, and tunes the weightings of the inputs to improve the accuracy of its predictions until they are optimised. The defining characteristic of machine learning algorithms, therefore, is that **the quality of their predictions improve with experience**. The more data we provide (usually up to a point), the better the prediction engines we can create

机器学习算法通过训练来学习。算法最初接收输出已知的示例，记录其预测与正确输出之间的差异，并调整输入的权重以提高其预测的准确性，直到它们被优化。因此，机器学习算法的决定性特征是**它们的预测质量会随着经验的增加而提高**。我们提供的数据越多（通常达到一定程度），我们可以创建的预测引擎就越好

Enter **deep learning (DL)**, which has revolutionised the world of artificial intelligence. Deep learning is a sub-set of machine learning — one of the more than 15 approaches to it. All deep learning is machine learning, but not all machine learning is deep learning

进入**深度学习 (DL)**，它彻底改变了人工智能的世界。深度学习是机器学习的一个子集——超过 15 种方法之一。所有深度学习都是机器学习，但并非所有机器学习都是深度学习。

Given its importance, it’s valuable to understand the basics of how deep learning works. Deep learning involves using an artificial ‘**neural network**’ — a collection of ‘neurons’ (software-based calculators) connected together.

鉴于其重要性，了解深度学习工作原理的基础知识很有价值。深度学习涉及使用人工“**神经网络**”——一组连接在一起的“神经元”（基于软件的计算器）。

An artificial neuron has one or more inputs. It performs a mathematical calculation based on these to deliver an output. The output will depend on both the ‘**weights**’ of each input and the configuration of ‘input-output function’ in the neuron (Figure 5, below). The input-output function can vary.

人工神经元有一个或多个输入。它基于这些执行数学计算以提供输出。输出将取决于每个输入的“**权重**”和神经元中“输入-输出函数”的配置

Neural networks are organised into multiple layers of neurons (hence ‘deep’ learning). The ‘input layer’ receives information the network will process — for example, a set of pictures. The ‘output layer’ provides the results. Between the input and output layers are ‘hidden layers’ where most activity occurs. Typically, the outputs of each neuron on one level of the neural network serve as one of the inputs for each of the neurons in the next layer

神经网络被组织成多层神经元（因此称为“深度”学习）。“输入层”接收网络将处理的信息——例如，一组图片。“输出层”提供结果。输入层和输出层之间是大多数活动发生的“隐藏层”。通常，神经网络一层上的每个神经元的输出作为下一层中每个神经元的输入之一

AI is important because it tackles profoundly difficult problems, and the solutions to those problems can be applied to sectors important to human wellbeing — ranging from health, education and commerce to transport, utilities and entertainment.

人工智能很重要，因为它解决了极其困难的问题，而这些问题的解决方案可以应用于对人类福祉至关重要的部门——从健康、教育和商业到交通、公用事业和娱乐.

Why is AI coming of age today?

为什么人工智能在今天成熟？

AI research began in the 1950s; after repeated false dawns, why is now the inflection point? The effectiveness of AI has been transformed in recent years due to the development of new algorithms, greater availability of data to inform them, better hardware to train them and cloud-based services to catalyse their adoption among developers.

人工智能研究始于 1950 年代；屡屡破晓，为何现在是拐点？近年来，由于新算法的开发、用于通知它们的数据的可用性提高、用于训练它们的更好的硬件以及基于云的服务促进它们在开发人员中的采用，人工智能的有效性在最近几年发生了转变。

What happens next?

The benefits of machine learning will be numerous and significant. Many will be visible, from autonomous vehicles to new methods of human-computer interaction. Many will be less apparent, but enable more capable and efficient day-to-day business processes and consumer services.

机器学习的好处将是巨大而重要的。从自动驾驶汽车到人机交互的新方法，许多都是可见的。许多将不那么明显，但能够实现更有能力和更高效的日常业务流程和消费者服务。

As with any paradigm shift, at times inflated expectations will exceed short-term potential. We expect a period of disillusionment regarding AI at some point in the future, to be followed by a longer and lasting recognition of its value as machine learning is used to improve and then reimagine existing systems.

与任何范式转变一样，过高的期望有时会超过短期潜力。我们预计在未来的某个时候，人工智能会出现一段幻灭期，随后随着机器学习被用于改进和重新构想现有系统，人们将对其价值有更长期和持久的认识。

Historically, industrial revolutions transformed production and communication through new sources of power and transmission. The first industrial revolution used steam power to mechanise production in the 1780s. The second used electricity to drive mass production in the 1870s. The third used electronics and software to automate production and communication from the 1970s. Today, as software eats the world, our primary source of value creation is the processing of information. By enabling us to do so more intelligently, machine learning will yield benefits both humble and historic.

从历史上看，工业革命通过新的能源和传输方式改变了生产和通讯方式。第一次工业革命在 1780 年代使用蒸汽动力实现生产机械化。第二次是在 1870 年代使用电力推动大规模生产。第三个使用电子和软件从 1970 年代开始自动化生产和通信。今天，随着软件吞噬世界，我们创造价值的主要来源是信息处理。通过使我们能够更智能地这样做，机器学习将产生既不起眼又具有历史意义的好处。
